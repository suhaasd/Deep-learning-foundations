{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7g7bxFCHxGP"
   },
   "source": [
    "$$\\Large\\boxed{\\text{AME 5202 Deep Learning, Even Semester 2026}}$$\n",
    "\n",
    "$$\\large\\text{Theme}: \\underline{\\text{Training a simple single-head attention model}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDK9fC6uiBGE"
   },
   "source": [
    "---\n",
    "\n",
    "Load essential libraries\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "20W0d4ruQjE4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x24a9fd306f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import random\n",
    "torch.manual_seed(0)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "import sys\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfYXkqmLiVLM"
   },
   "source": [
    "---\n",
    "\n",
    "Mount Google Drive folder if running Google Colab\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VYzBBBxqiaGa"
   },
   "outputs": [],
   "source": [
    "## Mount Google drive folder if running in Colab\n",
    "if('google.colab' in sys.modules):\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount = True)\n",
    "    DIR = '/content/drive/MyDrive/Colab Notebooks/MAHE/MSIS Coursework/EvenSem2026MAHE'\n",
    "    DATA_DIR = DIR+'/Data/'\n",
    "else:\n",
    "    DATA_DIR = 'Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Setup vocabulary including polysemous words (same sound different meaning)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size is 33\n"
     ]
    }
   ],
   "source": [
    "# Setup vocabulary\n",
    "vocab = [\n",
    "    \"[PAD]\", \"[MASK]\", \"[UNK]\",\n",
    "\n",
    "    \"I\", \"you\", \"we\", \"they\",\n",
    "\n",
    "    # Polysemous words\n",
    "    \"bear\",        # animal / tolerate\n",
    "    \"run\",         # move / operate\n",
    "    \"bank\",        # river / finance\n",
    "    \"charge\",      # legal / electrical\n",
    "\n",
    "    # Nouns\n",
    "    \"river\", \"road\", \"field\", \"court\", \"battery\",\n",
    "    \"money\", \"load\", \"power\", \"side\", \"shore\", \"swam\",\n",
    "\n",
    "    # Function words\n",
    "    \"to\", \"the\", \"a\", \"other\", \"across\", \"with\", \"in\", \"on\", \"of\", \"get\", \"cannot\"\n",
    "]\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "print(f'Vocabulary size is {vocab_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Create word-to-index and index-to-word dictionaries\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word-to-index dictionarty:\n",
      " {'[PAD]': 0, '[MASK]': 1, '[UNK]': 2, 'I': 3, 'you': 4, 'we': 5, 'they': 6, 'bear': 7, 'run': 8, 'bank': 9, 'charge': 10, 'river': 11, 'road': 12, 'field': 13, 'court': 14, 'battery': 15, 'money': 16, 'load': 17, 'power': 18, 'side': 19, 'shore': 20, 'swam': 21, 'to': 22, 'the': 23, 'a': 24, 'other': 25, 'across': 26, 'with': 27, 'in': 28, 'on': 29, 'of': 30, 'get': 31, 'cannot': 32}\n",
      "index-to-word dictionarty:\n",
      " {0: '[PAD]', 1: '[MASK]', 2: '[UNK]', 3: 'I', 4: 'you', 5: 'we', 6: 'they', 7: 'bear', 8: 'run', 9: 'bank', 10: 'charge', 11: 'river', 12: 'road', 13: 'field', 14: 'court', 15: 'battery', 16: 'money', 17: 'load', 18: 'power', 19: 'side', 20: 'shore', 21: 'swam', 22: 'to', 23: 'the', 24: 'a', 25: 'other', 26: 'across', 27: 'with', 28: 'in', 29: 'on', 30: 'of', 31: 'get', 32: 'cannot'}\n"
     ]
    }
   ],
   "source": [
    "# word-to-index and index-to-word dictionarties\n",
    "word_to_idx = {w: i for i, w in enumerate(vocab)}\n",
    "idx_to_word = {i: w for w, i in word_to_idx.items()}\n",
    "print(f'word-to-index dictionarty:\\n {word_to_idx}')\n",
    "print(f'index-to-word dictionarty:\\n {idx_to_word}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Create training data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "training_data = [\n",
    "    ([\"I\", \"swam\", \"across\", \"the\", \"river\", \"to\", \"the\", \"other\", \"[MASK]\"], \"shore\"),\n",
    "    ([\"they\", \"went\", \"to\", \"the\", \"bank\", \"to\", \"get\", \"[MASK]\"], \"money\"),\n",
    "    ([\"I\", \"saw\", \"a\", \"bear\", \"in\", \"the\", \"[MASK]\"], \"field\"),\n",
    "    ([\"I\", \"cannot\", \"bear\", \"the\", \"[MASK]\"], \"load\"),\n",
    "    ([\"they\", \"run\", \"across\", \"the\", \"[MASK]\"], \"field\"),\n",
    "    ([\"the\", \"battery\", \"can\", \"run\", \"with\", \"[MASK]\"], \"power\"),\n",
    "    ([\"the\", \"court\", \"will\", \"charge\", \"them\", \"with\", \"[MASK]\"], \"money\"),\n",
    "    ([\"the\", \"battery\", \"has\", \"a\", \"charge\", \"of\", \"[MASK]\"], \"power\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "A simple encoder function\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder function\n",
    "def encode(sentence):\n",
    "    return torch.tensor([word_to_idx.get(w, word_to_idx[\"[UNK]\"]) for w in sentence])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Testing the encoder function\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 3, 21, 26, 23, 11, 22, 23, 25,  1])\n"
     ]
    }
   ],
   "source": [
    "sentence = [\"I\", \"swam\", \"across\", \"the\", \"river\", \"to\", \"the\", \"other\", \"[MASK]\"]\n",
    "input_ids = encode(sentence)\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "An example demonstrating how to create embeddings which are random and trainable vector representations of words that are stored in a simple lookup table\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1258e+00, -1.1524e+00, -2.5058e-01, -4.3388e-01,  8.4871e-01,\n",
      "          6.9201e-01, -3.1601e-01, -2.1152e+00],\n",
      "        [ 3.2227e-01, -1.2633e+00,  3.4998e-01,  3.0813e-01,  1.1984e-01,\n",
      "          1.2377e+00,  1.1168e+00, -2.4728e-01],\n",
      "        [-1.3527e+00, -1.6959e+00,  5.6665e-01,  7.9351e-01,  5.9884e-01,\n",
      "         -1.5551e+00, -3.4136e-01,  1.8530e+00],\n",
      "        [ 7.5019e-01, -5.8550e-01, -1.7340e-01,  1.8348e-01,  1.3894e+00,\n",
      "          1.5863e+00,  9.4630e-01, -8.4368e-01],\n",
      "        [-6.1358e-01,  3.1593e-02, -4.9268e-01,  2.4841e-01,  4.3970e-01,\n",
      "          1.1241e-01,  6.4079e-01,  4.4116e-01],\n",
      "        [-1.0231e-01,  7.9244e-01, -2.8967e-01,  5.2507e-02,  5.2286e-01,\n",
      "          2.3022e+00, -1.4689e+00, -1.5867e+00],\n",
      "        [-6.7309e-01,  8.7283e-01,  1.0554e+00,  1.7784e-01, -2.3034e-01,\n",
      "         -3.9175e-01,  5.4329e-01, -3.9516e-01],\n",
      "        [-4.4622e-01,  7.4402e-01,  1.5210e+00,  3.4105e+00, -1.5312e+00,\n",
      "         -1.2341e+00,  1.8197e+00, -5.5153e-01],\n",
      "        [-5.6925e-01,  9.1997e-01,  1.1108e+00,  1.2899e+00, -1.4782e+00,\n",
      "          2.5672e+00, -4.7312e-01,  3.3555e-01],\n",
      "        [-1.6293e+00, -5.4974e-01, -4.7983e-01, -4.9968e-01, -1.0670e+00,\n",
      "          1.1149e+00, -1.4067e-01,  8.0575e-01],\n",
      "        [-9.3348e-02,  6.8705e-01, -8.3832e-01,  8.9182e-04,  8.4189e-01,\n",
      "         -4.0003e-01,  1.0395e+00,  3.5815e-01],\n",
      "        [-2.4600e-01,  2.3025e+00, -1.8817e+00, -4.9727e-02, -1.0450e+00,\n",
      "         -9.5650e-01,  3.3532e-02,  7.1009e-01],\n",
      "        [ 1.6459e+00, -1.3602e+00,  3.4457e-01,  5.1987e-01, -2.6133e+00,\n",
      "         -1.6965e+00, -2.2824e-01,  2.7995e-01],\n",
      "        [ 2.4693e-01,  7.6887e-02,  3.3801e-01,  4.5440e-01,  4.5694e-01,\n",
      "         -8.6537e-01,  7.8131e-01, -9.2679e-01],\n",
      "        [-2.1883e-01, -2.4351e+00, -7.2915e-02, -3.3986e-02,  9.6252e-01,\n",
      "          3.4917e-01, -9.2146e-01, -5.6195e-02],\n",
      "        [-6.2270e-01, -4.6372e-01,  1.9218e+00, -4.0255e-01,  1.2390e-01,\n",
      "          1.1648e+00,  9.2337e-01,  1.3873e+00],\n",
      "        [-8.8338e-01, -4.1891e-01, -8.0483e-01,  5.6561e-01,  6.1036e-01,\n",
      "          4.6688e-01,  1.9507e+00, -1.0631e+00],\n",
      "        [-7.7326e-02,  1.1640e-01, -5.9399e-01, -1.2439e+00, -1.0209e-01,\n",
      "         -1.0335e+00, -3.1264e-01,  2.4579e-01],\n",
      "        [-2.5964e-01,  1.1834e-01,  2.4396e-01,  1.1646e+00,  2.8858e-01,\n",
      "          3.8660e-01, -2.0106e-01, -1.1793e-01],\n",
      "        [ 1.9220e-01, -7.7216e-01, -1.9003e+00,  1.3068e-01, -7.0429e-01,\n",
      "          3.1472e-01,  1.5739e-01,  3.8536e-01],\n",
      "        [ 9.6715e-01, -9.9108e-01,  3.0161e-01, -1.0732e-01,  9.9846e-01,\n",
      "         -4.9871e-01,  7.6111e-01,  6.1830e-01],\n",
      "        [ 3.1405e-01,  2.1333e-01, -1.2005e-01,  3.6046e-01, -3.1403e-01,\n",
      "         -1.0787e+00,  2.4081e-01, -1.3962e+00],\n",
      "        [-6.6144e-02, -3.5836e-01, -1.5616e+00, -3.5464e-01,  1.0811e+00,\n",
      "          1.3148e-01,  1.5735e+00,  7.8143e-01],\n",
      "        [-1.0787e+00, -7.2091e-01,  1.4708e+00,  2.7564e-01,  6.6678e-01,\n",
      "         -9.9439e-01, -1.1894e+00, -1.1959e+00],\n",
      "        [-5.5963e-01,  5.3347e-01,  4.0689e-01,  3.9459e-01,  1.7151e-01,\n",
      "          8.7604e-01, -2.8709e-01,  1.0216e+00],\n",
      "        [-7.4395e-02, -1.0922e+00,  3.9203e-01,  5.9453e-01,  6.6227e-01,\n",
      "         -1.2063e+00,  6.0744e-01, -5.4716e-01],\n",
      "        [ 1.1711e+00,  9.7496e-02,  9.6337e-01,  8.4032e-01, -1.2537e+00,\n",
      "          9.8684e-01, -4.9466e-01, -1.2830e+00],\n",
      "        [ 9.5522e-01,  1.2836e+00, -6.6586e-01,  5.6513e-01,  2.8770e-01,\n",
      "         -3.3375e-02, -1.0619e+00, -1.1443e-01],\n",
      "        [-3.4334e-01,  1.5713e+00,  1.9161e-01,  3.7994e-01, -1.4476e-01,\n",
      "          6.3762e-01, -2.8129e-01, -1.3299e+00],\n",
      "        [-1.4201e-01, -5.3415e-01, -5.2338e-01,  8.6150e-01, -8.8696e-01,\n",
      "          8.3877e-01,  1.1529e+00, -1.7611e+00],\n",
      "        [-1.4777e+00, -1.7557e+00,  7.6166e-02, -1.0786e+00,  1.4403e+00,\n",
      "         -1.1059e-01,  5.7686e-01, -1.6917e-01],\n",
      "        [ 1.4903e+00, -7.0053e-01,  1.8056e-01,  1.3615e+00,  2.0372e+00,\n",
      "          6.4304e-01, -7.3257e-01, -4.8771e-01],\n",
      "        [ 2.5783e-01, -5.6502e-01,  9.2781e-01,  4.8258e-01, -8.2979e-01,\n",
      "          1.2678e+00,  2.7356e-01, -6.1465e-01]])\n",
      "tensor([[ 0.7502, -0.5855, -0.1734,  0.1835,  1.3894,  1.5863,  0.9463, -0.8437],\n",
      "        [ 0.3140,  0.2133, -0.1201,  0.3605, -0.3140, -1.0787,  0.2408, -1.3962],\n",
      "        [ 1.1711,  0.0975,  0.9634,  0.8403, -1.2537,  0.9868, -0.4947, -1.2830],\n",
      "        [-1.0787, -0.7209,  1.4708,  0.2756,  0.6668, -0.9944, -1.1894, -1.1959],\n",
      "        [-0.2460,  2.3025, -1.8817, -0.0497, -1.0450, -0.9565,  0.0335,  0.7101],\n",
      "        [-0.0661, -0.3584, -1.5616, -0.3546,  1.0811,  0.1315,  1.5735,  0.7814],\n",
      "        [-1.0787, -0.7209,  1.4708,  0.2756,  0.6668, -0.9944, -1.1894, -1.1959],\n",
      "        [-0.0744, -1.0922,  0.3920,  0.5945,  0.6623, -1.2063,  0.6074, -0.5472],\n",
      "        [ 0.3223, -1.2633,  0.3500,  0.3081,  0.1198,  1.2377,  1.1168, -0.2473]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 8\n",
    "embed = nn.Embedding(vocab_size, embedding_size)\n",
    "# The initial random embeddings matrix corresponding to all\n",
    "# words in the vocabulary\n",
    "print(embed.weight.data)\n",
    "#print('----')\n",
    "\n",
    "# Extract the embeddings of the words in the sentence\n",
    "print(embed(input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Creating linear operators that are random and trainable (equivalent to weights)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'swam', 'across', 'the', 'river', 'to', 'the', 'other', '[MASK]']\n",
      "-----\n",
      "tensor([ 3, 21, 26, 23, 11, 22, 23, 25,  1])\n",
      "-----\n",
      "tensor([[ 0.7502, -0.5855, -0.1734,  0.1835,  1.3894,  1.5863,  0.9463, -0.8437],\n",
      "        [ 0.3140,  0.2133, -0.1201,  0.3605, -0.3140, -1.0787,  0.2408, -1.3962],\n",
      "        [ 1.1711,  0.0975,  0.9634,  0.8403, -1.2537,  0.9868, -0.4947, -1.2830],\n",
      "        [-1.0787, -0.7209,  1.4708,  0.2756,  0.6668, -0.9944, -1.1894, -1.1959],\n",
      "        [-0.2460,  2.3025, -1.8817, -0.0497, -1.0450, -0.9565,  0.0335,  0.7101],\n",
      "        [-0.0661, -0.3584, -1.5616, -0.3546,  1.0811,  0.1315,  1.5735,  0.7814],\n",
      "        [-1.0787, -0.7209,  1.4708,  0.2756,  0.6668, -0.9944, -1.1894, -1.1959],\n",
      "        [-0.0744, -1.0922,  0.3920,  0.5945,  0.6623, -1.2063,  0.6074, -0.5472],\n",
      "        [ 0.3223, -1.2633,  0.3500,  0.3081,  0.1198,  1.2377,  1.1168, -0.2473]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "-----\n",
      "tensor([ 0.5514,  0.2155,  0.0192,  0.0889,  0.3303,  0.8560, -0.2483, -0.3949,\n",
      "        -0.1103, -0.4463,  1.2458, -0.6182, -0.1523, -0.0945,  0.0732,  0.0949,\n",
      "        -0.9202, -0.3305,  0.0678,  0.0750,  0.2839,  0.8322, -0.4732, -0.4034,\n",
      "         0.2316,  0.8018,  0.4845,  0.9753,  0.2798,  0.2256,  0.2199,  0.0531,\n",
      "         0.1475], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "W = nn.Linear(8, 33)\n",
    "#print(W.weight.data)\n",
    "\n",
    "# Training sample-0\n",
    "input_data = training_data[0][0]\n",
    "print(input_data)\n",
    "print('-----')\n",
    "\n",
    "# Encoded input data\n",
    "print(encode(input_data))\n",
    "print('-----')\n",
    "\n",
    "# Embeddings corresponding to the tokens in the input data\n",
    "X = embed(encode(input_data))\n",
    "print(X)\n",
    "print('-----')\n",
    "\n",
    "# The linear operator W applied to the embeddings of the [MASK] token\n",
    "print(W(X[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "A tiny transformer class implementing the single-head self-attention model\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiny transformer class\n",
    "class TinyTransformer(nn.Module):\n",
    "  def __init__(self, vocab_size, d_model):\n",
    "    super().__init__()\n",
    "\n",
    "    # Initialize embeddings for the words in the vocabulary\n",
    "    self.embed = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "    # Initialize the query, key, and value linear operators\n",
    "    self.W_Q = nn.Linear(d_model, d_model, bias = False)\n",
    "    self.W_K = nn.Linear(d_model, d_model, bias = False)\n",
    "    self.W_V = nn.Linear(d_model, d_model, bias = False)\n",
    "\n",
    "    # Initialize the linear operator for the output layer\n",
    "    self.output = nn.Linear(d_model, vocab_size)\n",
    "        \n",
    "  def forward(self, input_ids, mask_index):\n",
    "    # Extract embeddings for the words in the sentence\n",
    "    X = self.embed(input_ids)                 \n",
    "\n",
    "    # Calculate the query, key, and value representations of the words\n",
    "    Q = self.W_Q(X) # same as torch.matmul(X, W_Q.data.weights)\n",
    "    K = self.W_K(X)\n",
    "    V = self.W_V(X)\n",
    "\n",
    "    # Calculate pairwise scaled self similarities a.k.a. the attention scores\n",
    "    S = F.softmax((Q @ K.T)/math.sqrt(K.size(-1)), dim = -1)\n",
    "\n",
    "    # Calculate the updated embeddings of the words weighted using the attention scores\n",
    "    X_context = S @ V   # Y = Self-Attention(X)            \n",
    "\n",
    "    # Extract the updated embedding for the missing [MASK] word\n",
    "    mask_embedding = X_context[mask_index]\n",
    "\n",
    "    # Calculate the raw scores (also called logits) for the missing [MASK] word\n",
    "    # w.r.t. all the other words in the vocabulary\n",
    "    z = self.output(mask_embedding)\n",
    "\n",
    "    return z, S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Define loss function\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 2.3960351717727737\n",
      "tensor([3.0475e-04, 1.8484e-04, 9.1078e-02, 9.0843e-01, 5.0898e-09],\n",
      "       dtype=torch.float64)\n",
      "Loss = 2.3960351717727737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sudarsan.acharya\\AppData\\Local\\Temp\\ipykernel_29948\\1748250464.py:5: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(logits)\n"
     ]
    }
   ],
   "source": [
    "logits = torch.tensor([1.0, 0.5, 6.7, 9.0, -10], dtype = torch.float64)\n",
    "target_idx = torch.tensor(2, dtype = torch.long)\n",
    "loss = F.cross_entropy(logits, target_idx)\n",
    "print(f'Loss = {loss}')\n",
    "probs = F.softmax(logits)\n",
    "print(probs)\n",
    "loss = -torch.log(probs[target_idx])\n",
    "print(f'Loss = {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def loss_fn(logits, target_idx):\n",
    "  probs = F.softmax(logits, dim = -1) # softmax-activated scores\n",
    "  eps = 1e-09\n",
    "  loss = -torch.log(probs[target_idx] + eps)\n",
    "  #print(f'loss = {loss}')\n",
    "  # Much quicker way of calculating the CCE loss using PyTorch\n",
    "  #loss = F.cross_entropy(logits, torch.tensor(target_idx, dtype = torch.long))\n",
    "  #print(f'loss = {loss}')\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Calculating the loss for a simple training sample\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['I', 'swam', 'across', 'the', 'river', 'to', 'the', 'other', '[MASK]'], 'shore')\n",
      "----\n",
      "tensor([ 3, 21, 26, 23, 11, 22, 23, 25,  1])\n",
      "----\n",
      "8\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "data = training_data[0]\n",
    "print(data)\n",
    "print('----')\n",
    "\n",
    "# Call enocder function\n",
    "input_ids = encode(data[0])\n",
    "print(input_ids)\n",
    "print('----')\n",
    "\n",
    "# Get the position of the missing [MASK] word\n",
    "mask_index = data[0].index(\"[MASK]\")\n",
    "print(mask_index)\n",
    "print('----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['I', 'swam', 'across', 'the', 'river', 'to', 'the', 'other', '[MASK]'], 'shore')\n",
      "----\n",
      "tensor([ 3, 21, 26, 23, 11, 22, 23, 25,  1])\n",
      "----\n",
      "8\n",
      "----\n",
      "20\n",
      "----\n",
      "tensor(3.6908, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "data = training_data[0]\n",
    "print(data)\n",
    "print('----')\n",
    "\n",
    "# Call enocder function\n",
    "input_ids = encode(data[0])\n",
    "print(input_ids)\n",
    "print('----')\n",
    "\n",
    "# Get the position of the missing [MASK] word\n",
    "mask_index = data[0].index(\"[MASK]\")\n",
    "print(mask_index)\n",
    "print('----')\n",
    "\n",
    "# Get the target word index\n",
    "target_idx = word_to_idx[data[1]]\n",
    "print(target_idx)\n",
    "print('----')\n",
    "\n",
    "# Apply the tiny transformer model\n",
    "model = TinyTransformer(vocab_size, 8)\n",
    "logits, _ = model(input_ids, mask_index)\n",
    "loss = loss_fn(logits, target_idx)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Training for the parameters of the model\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x0000024A9B47E180>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TinyTransformer(vocab_size = vocab_size, d_model = 8)\n",
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 | Loss: 27.8455\n",
      "Epoch  10 | Loss: 4.3334\n",
      "Epoch  20 | Loss: 4.0115\n",
      "Epoch  30 | Loss: 0.2210\n",
      "Epoch  40 | Loss: 0.0207\n",
      "Epoch  50 | Loss: 0.0107\n",
      "Epoch  60 | Loss: 0.0068\n",
      "Epoch  70 | Loss: 0.0048\n",
      "Epoch  80 | Loss: 0.0036\n",
      "Epoch  90 | Loss: 0.0028\n",
      "Epoch 100 | Loss: 0.0022\n",
      "Epoch 110 | Loss: 0.0018\n",
      "Epoch 120 | Loss: 0.0015\n",
      "Epoch 130 | Loss: 0.0013\n",
      "Epoch 140 | Loss: 0.0011\n",
      "Epoch 150 | Loss: 0.0010\n",
      "Epoch 160 | Loss: 0.0008\n",
      "Epoch 170 | Loss: 0.0007\n",
      "Epoch 180 | Loss: 0.0007\n",
      "Epoch 190 | Loss: 0.0006\n",
      "Epoch 200 | Loss: 0.0005\n",
      "Epoch 210 | Loss: 0.0005\n",
      "Epoch 220 | Loss: 0.0004\n",
      "Epoch 230 | Loss: 0.0004\n",
      "Epoch 240 | Loss: 0.0004\n",
      "Epoch 250 | Loss: 0.0003\n",
      "Epoch 260 | Loss: 0.0003\n",
      "Epoch 270 | Loss: 0.0003\n",
      "Epoch 280 | Loss: 0.0003\n",
      "Epoch 290 | Loss: 0.0002\n",
      "Epoch 300 | Loss: 0.0002\n",
      "Epoch 310 | Loss: 0.0002\n",
      "Epoch 320 | Loss: 0.0002\n",
      "Epoch 330 | Loss: 0.0002\n",
      "Epoch 340 | Loss: 0.0002\n",
      "Epoch 350 | Loss: 0.0002\n",
      "Epoch 360 | Loss: 0.0001\n",
      "Epoch 370 | Loss: 0.0001\n",
      "Epoch 380 | Loss: 0.0001\n",
      "Epoch 390 | Loss: 0.0001\n",
      "Epoch 400 | Loss: 0.0001\n",
      "Epoch 410 | Loss: 0.0001\n",
      "Epoch 420 | Loss: 0.0001\n",
      "Epoch 430 | Loss: 0.0001\n",
      "Epoch 440 | Loss: 0.0001\n",
      "Epoch 450 | Loss: 0.0001\n",
      "Epoch 460 | Loss: 0.0001\n",
      "Epoch 470 | Loss: 0.0001\n",
      "Epoch 480 | Loss: 0.0001\n",
      "Epoch 490 | Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = TinyTransformer(vocab_size = vocab_size, d_model = 8)\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.05)\n",
    "\n",
    "# Optimization loop\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "  loss_epoch = 0.0\n",
    "  random.shuffle(training_data)\n",
    "\n",
    "  for sentence, target_word in training_data:\n",
    "    input_ids = encode(sentence)\n",
    "    mask_index = sentence.index(\"[MASK]\")\n",
    "    target_id = word_to_idx[target_word]\n",
    "    \n",
    "    # Zero out the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward propagation\n",
    "    logits, _ = model(input_ids, mask_index)\n",
    "    loss = loss_fn(logits, target_id)\n",
    "\n",
    "    # Backward propagation and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()model = TinyTransformer(vocab_size = vocab_size, d_model = 8)\n",
    "    loss_epoch += loss.item()\n",
    "  \n",
    "  # Print the loss every 10 epochs\n",
    "  if epoch % 10 == 0:\n",
    "    print(f\"Epoch {epoch:3d} | Loss: {loss_epoch:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Prediction function\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "  input_ids = encode(sentence)\n",
    "  mask_index = sentence.index(\"[MASK]\")\n",
    "\n",
    "  with torch.no_grad():\n",
    "    logits, attention = model(input_ids, mask_index)\n",
    "    pred_id = logits.argmax().item()\n",
    "\n",
    "  return idx_to_word[pred_id], attention[mask_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Test the model\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence: I ran along the bank to the [MASK]\n",
      "Prediction: money\n",
      "Attention from [MASK]:\n",
      "  I          → 0.000\n",
      "  ran        → 0.000\n",
      "  along      → 0.000\n",
      "  the        → 0.000\n",
      "  bank       → 1.000\n",
      "  to         → 0.000\n",
      "  the        → 0.000\n",
      "  [MASK]     → 0.000\n",
      "\n",
      "Sentence: the battery cannot run without [MASK]\n",
      "Prediction: load\n",
      "Attention from [MASK]:\n",
      "  the        → 0.000\n",
      "  battery    → 0.000\n",
      "  cannot     → 1.000\n",
      "  run        → 0.000\n",
      "  without    → 0.000\n",
      "  [MASK]     → 0.000\n",
      "\n",
      "Sentence: the court will charge the bank with [MASK]\n",
      "Prediction: money\n",
      "Attention from [MASK]:\n",
      "  the        → 0.000\n",
      "  court      → 0.023\n",
      "  will       → 0.000\n",
      "  charge     → 0.000\n",
      "  the        → 0.000\n",
      "  bank       → 0.977\n",
      "  with       → 0.000\n",
      "  [MASK]     → 0.000\n",
      "\n",
      "Sentence: the bear on the bank could not bear the [MASK]\n",
      "Prediction: money\n",
      "Attention from [MASK]:\n",
      "  the        → 0.000\n",
      "  bear       → 0.000\n",
      "  on         → 0.000\n",
      "  the        → 0.000\n",
      "  bank       → 1.000\n",
      "  could      → 0.000\n",
      "  not        → 0.000\n",
      "  bear       → 0.000\n",
      "  the        → 0.000\n",
      "  [MASK]     → 0.000\n",
      "\n",
      "Sentence: I swam across the [MASK] to get the battery\n",
      "Prediction: shore\n",
      "Attention from [MASK]:\n",
      "  I          → 0.004\n",
      "  swam       → 0.000\n",
      "  across     → 0.380\n",
      "  the        → 0.000\n",
      "  [MASK]     → 0.000\n",
      "  to         → 0.000\n",
      "  get        → 0.615\n",
      "  the        → 0.000\n",
      "  battery    → 0.000\n"
     ]
    }
   ],
   "source": [
    "# Model testing\n",
    "test_data = [\n",
    "    [\"I\", \"ran\", \"along\", \"the\", \"bank\", \"to\", \"the\", \"[MASK]\"],\n",
    "    [\"the\", \"battery\", \"cannot\", \"run\", \"without\", \"[MASK]\"],\n",
    "    [\"the\", \"court\", \"will\", \"charge\", \"the\", \"bank\", \"with\", \"[MASK]\"],\n",
    "    [\"the\", \"bear\", \"on\", \"the\", \"bank\", \"could\", \"not\", \"bear\", \"the\", \"[MASK]\"],\n",
    "    [\"I\", \"swam\", \"across\", \"the\", \"[MASK]\", \"to\", \"get\", \"the\", \"battery\"]\n",
    "]\n",
    "\n",
    "for sentence in test_data:\n",
    "  prediction, attention = predict(sentence)\n",
    "  print(\"\\nSentence:\", \" \".join(sentence))\n",
    "  print(\"Prediction:\", prediction)\n",
    "  print(\"Attention from [MASK]:\")\n",
    "  for w, a in zip(sentence, attention):\n",
    "    print(f\"  {w:10s} → {a:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "colab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
