{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7g7bxFCHxGP"
      },
      "source": [
        "$$\\Large\\boxed{\\text{AME 5202 Deep Learning, Even Semester 2026}}$$\n",
        "\n",
        "$$\\large\\text{Theme}: \\underline{\\text{linear algebra computational foundation for deep learning}}$$"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9D0JpiiLaFJ",
        "outputId": "cb3c7424-56e2-4e53-eb53-7904027b737b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDK9fC6uiBGE"
      },
      "source": [
        "---\n",
        "\n",
        "Load essential libraries\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20W0d4ruQjE4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('dark_background')\n",
        "%matplotlib inline\n",
        "import sys\n",
        "import pickle\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfYXkqmLiVLM"
      },
      "source": [
        "---\n",
        "\n",
        "Mount Google Drive folder if running Google Colab\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYzBBBxqiaGa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2596bee6-6710-4aa1-c36e-68a76a776f72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "## Mount Google drive folder if running in Colab\n",
        "if('google.colab' in sys.modules):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount = True)\n",
        "    DIR = '/content/drive/MyDrive/Colab Notebooks/datasets/glove_wiki_gigaword_50.pkl'\n",
        "\n",
        "else:\n",
        "    DATA_DIR = 'Data/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avVZ6D1ZgEUT"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**We will now use PyTorch to create tensors**\n",
        "\n",
        "The patient data matrix:\n",
        "\n",
        "![patient data matrix](https://1drv.ms/i/s!AjTcbXuSD3I3hsxIkL4V93-CGq8RkQ?embed=1&width=1000)\n",
        "\n",
        "**Notation**:\n",
        "\n",
        "Zeroth patient vector $\\mathbf{x}^{(0)}= \\begin{bmatrix}72\\\\120\\\\37.3\\\\104\\\\32.5\\end{bmatrix}$ and zeroth feature (heart rate vector) $\\mathbf{x}_0 = \\begin{bmatrix}72\\\\85\\\\68\\\\90\\\\84\\\\78\\end{bmatrix}.$\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrPnepAEvr0O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "648188f9-89e9-4b29-db08-f25a1b8959d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 72.0000, 120.0000,  37.3000, 104.0000,  32.5000],\n",
            "        [ 85.0000, 130.0000,  37.0000, 110.0000,  14.0000],\n",
            "        [ 68.0000, 110.0000,  38.5000, 125.0000,  34.0000],\n",
            "        [ 90.0000, 140.0000,  38.0000, 130.0000,  26.0000],\n",
            "        [ 84.0000, 132.0000,  38.3000, 146.0000,  30.0000],\n",
            "        [ 78.0000, 128.0000,  37.2000, 102.0000,  12.0000]],\n",
            "       dtype=torch.float64)\n",
            "torch.Size([6, 5])\n",
            "<class 'torch.Tensor'>\n",
            "tensor([ 72.0000, 120.0000,  37.3000, 104.0000,  32.5000], dtype=torch.float64)\n",
            "tensor([ 72.0000, 120.0000,  37.3000, 104.0000,  32.5000], dtype=torch.float64)\n",
            "tensor(37.3000, dtype=torch.float64)\n",
            "tensor([ 78.0000, 128.0000,  37.2000, 102.0000,  12.0000], dtype=torch.float64)\n",
            "tensor([120., 130., 110., 140., 132., 128.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "## Create a patient data matrix as a constant tensor\n",
        "X = torch.tensor([\n",
        "                  [72, 120, 37.3, 104, 32.5],\n",
        "                  [85, 130, 37.0, 110, 14],\n",
        "                  [68, 110, 38.5, 125, 34],\n",
        "                  [90, 140, 38.0, 130, 26],\n",
        "                  [84,132,38.3,146,30],\n",
        "                  [78,128,37.2,102,12]\n",
        "                  ],\n",
        "                  dtype = torch.float64)\n",
        "print(X)\n",
        "print(X.shape)\n",
        "print(type(X))\n",
        "print(X[0]) #this is the patient 0 information which is rank 1 tensor\n",
        "print(X[0, :]) #this wil also print the patient 0 information\n",
        "print(X[0,2]) # feature 2 (temperature) od patient 0\n",
        "print(X[-1]) #this is the last patient (patient 5 ) information\n",
        "print(X[:, 1]) # this is feature 1(BP) of all the patients\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cevtn_b4gek5"
      },
      "source": [
        "---\n",
        "\n",
        "**Convert a PyTorch object into a numpy array**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asfhe6rdKi0N",
        "outputId": "18fe1690-7f81-4b57-bd57-c37de3d60846"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 72. , 120. ,  37.3, 104. ,  32.5],\n",
              "       [ 85. , 130. ,  37. , 110. ,  14. ],\n",
              "       [ 68. , 110. ,  38.5, 125. ,  34. ],\n",
              "       [ 90. , 140. ,  38. , 130. ,  26. ],\n",
              "       [ 84. , 132. ,  38.3, 146. ,  30. ],\n",
              "       [ 78. , 128. ,  37.2, 102. ,  12. ]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "X.detach().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS3MmzwsgkWU"
      },
      "source": [
        "---\n",
        "\n",
        "**Addition and subtraction of vectors, scalar multiplication (apply operation componentwise)**\n",
        "\n",
        "![vector addition](https://1drv.ms/i/c/37720f927b6ddc34/IQQ03G17kg9yIIA3NokBAAAAAZLAaAoWwhtn8Vk26NotALo?width=256)\n",
        "\n",
        "![vector subtracton](https://1drv.ms/i/c/37720f927b6ddc34/IQQ03G17kg9yIIA3M4kBAAAAAU_n_mAEv006QFZm_sUj2Dc?width=256)\n",
        "\n",
        "![vector multiplication](https://1drv.ms/i/c/37720f927b6ddc34/IQQ03G17kg9yIIA3NIkBAAAAAa_qL04bLT4kWoNeHcrR9LQ?width=256)\n",
        "\n",
        "![vector geometry1](https://1drv.ms/i/c/37720f927b6ddc34/IQSGNMr5z3SSRry7LSKL7LybAcGYuzgw5smabV8-6DudXIs?width=230)\n",
        "\n",
        "![vector geometry2](https://1drv.ms/i/c/37720f927b6ddc34/IQQ03G17kg9yIIA3WokBAAAAAQi8FPV9YCebl5WnyEKJ3vg?width=213&height=192)\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "rank 0 -scalar values\n",
        "\n",
        "rank 1 - 1dimension\n",
        "\n",
        "rank 2 - 2 dimension (matrix)"
      ],
      "metadata": {
        "id": "hH8SwcsZj-xq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(9/5) * X[:,2] +32      #broadcasting happens here"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miXqQrRsjllv",
        "outputId": "bcd07b27-0376-4dea-d50b-3ce2694a3b5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 99.1400,  98.6000, 101.3000, 100.4000, 100.9400,  98.9600],\n",
              "       dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_avg = (1/6)*(X[0, :] + X[1, :] + X[2, :] + X[3, :] + X[4, :] + X[5, :])\n",
        "print(x_avg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f47UtvQulKK3",
        "outputId": "2e5d8301-7ee7-4aa6-ca41-9306c1332cee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 79.5000, 126.6667,  37.7167, 119.5000,  24.7500], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(X, dim=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ujvP3V6k7pg",
        "outputId": "74a1b988-50b3-4b96-9a2f-e870abb59999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 79.5000, 126.6667,  37.7167, 119.5000,  24.7500], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgPtJP0sglQP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93050a6c-6082-4595-8c80-3c8c3ad6d036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([153.0000, 240.0000,  75.5000, 235.0000,  48.0000], dtype=torch.float64)\n",
            "#############################\n",
            "tensor([ 17.0000,  20.0000,  -1.5000, -15.0000, -20.0000], dtype=torch.float64)\n",
            "#############################\n",
            "tensor([ 79.5000, 126.6667,  37.7167, 119.5000,  24.7500], dtype=torch.float64)\n",
            "#############################\n",
            "tensor([ 79.5000, 126.6667,  37.7167, 119.5000,  24.7500], dtype=torch.float64)\n",
            "#############################\n",
            "tensor([[ -7.5000,  -6.6667,  -0.4167, -15.5000,   7.7500],\n",
            "        [  5.5000,   3.3333,  -0.7167,  -9.5000, -10.7500],\n",
            "        [-11.5000, -16.6667,   0.7833,   5.5000,   9.2500],\n",
            "        [ 10.5000,  13.3333,   0.2833,  10.5000,   1.2500],\n",
            "        [  4.5000,   5.3333,   0.5833,  26.5000,   5.2500],\n",
            "        [ -1.5000,   1.3333,  -0.5167, -17.5000, -12.7500]],\n",
            "       dtype=torch.float64)\n",
            "#############################\n"
          ]
        }
      ],
      "source": [
        "# Vector addition\n",
        "print(X[1, :] + X[2, :])\n",
        "\n",
        "print(\"#############################\")\n",
        "\n",
        "# Vector subtraction\n",
        "print(X[1, :] - X[2, :])\n",
        "\n",
        "print(\"#############################\")\n",
        "# Scalar-vector multiplication\n",
        "(9/5) * X[:, 2] + 32 # Temperature in Fahrenheit\n",
        "\n",
        "\n",
        "# Average patient\n",
        "x_avg = (1/6)*(X[0, :] + X[1, :] + X[2, :] + X[3, :] + X[4, :] + X[5, :])\n",
        "print(x_avg)\n",
        "print(\"#############################\")\n",
        "# Using the in-built torch function\n",
        "x_avg = torch.mean(X, dim=0)\n",
        "print(x_avg)\n",
        "print(\"#############################\")\n",
        "\n",
        "# Another broadcasting example\n",
        "print(X - x_avg)\n",
        "print(\"#############################\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t_qXrlCROKA"
      },
      "source": [
        "---\n",
        "\n",
        "Application of vector subtraction in natural language processing (NLP): download the word embedding model trained on Wikipedia articles.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3_SM-1-gwoe"
      },
      "outputs": [],
      "source": [
        "# Load the Wikipedia-trained GLoVe word vectors (50-dimensional) from the pickle file\n",
        "with open(DIR , 'rb') as f:\n",
        "    loaded_word_vectors = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_word_vectors.get('king')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPXeVDqcpgRo",
        "outputId": "44d76152-b12b-4e60-a919-079c97e25d5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.50451 ,  0.68607 , -0.59517 , -0.022801,  0.60046 , -0.13498 ,\n",
              "       -0.08813 ,  0.47377 , -0.61798 , -0.31012 , -0.076666,  1.493   ,\n",
              "       -0.034189, -0.98173 ,  0.68229 ,  0.81722 , -0.51874 , -0.31503 ,\n",
              "       -0.55809 ,  0.66421 ,  0.1961  , -0.13495 , -0.11476 , -0.30344 ,\n",
              "        0.41177 , -2.223   , -1.0756  , -1.0783  , -0.34354 ,  0.33505 ,\n",
              "        1.9927  , -0.04234 , -0.64319 ,  0.71125 ,  0.49159 ,  0.16754 ,\n",
              "        0.34344 , -0.25663 , -0.8523  ,  0.1661  ,  0.40102 ,  1.1685  ,\n",
              "       -1.0137  , -0.21585 , -0.15155 ,  0.78321 , -0.91241 , -1.6106  ,\n",
              "       -0.64426 , -0.51042 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_word_vectors.get('king') - loaded_word_vectors.get('queen')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMkbmInUp8Sw",
        "outputId": "98c38018-dab4-414b-d884-87176ef7e1c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.12596998, -1.1372299 ,  0.66962993,  0.081499  ,  0.24217   ,\n",
              "       -0.73527   ,  0.08725001, -0.36390004, -0.561182  ,  0.44783002,\n",
              "       -0.30347598,  0.50713   , -0.640059  , -0.66753995,  0.39352003,\n",
              "        0.25708997,  0.25581998, -0.386451  ,  0.01601005,  0.45079002,\n",
              "       -0.38064003, -0.52175   ,  0.01098001, -0.58356   ,  0.13042   ,\n",
              "       -0.41770005, -0.03350008, -0.88575   ,  0.21020997,  0.389576  ,\n",
              "        0.4353    , -0.43530002, -0.39569002,  0.36874   ,  0.03794   ,\n",
              "        0.00517   , -0.18120003, -0.186358  , -0.01485997,  1.1987001 ,\n",
              "       -0.05844   ,  0.91547996, -0.83533   ,  0.51813   ,  0.0487    ,\n",
              "        0.54850996, -0.35146004,  0.6733    , -0.6535353 ,  0.09241998],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YRVJferRlK5"
      },
      "source": [
        "---\n",
        "\n",
        "Now we will see what embedding vector comes as a result of applying the model for the words *cricket* and *football*.\n",
        "\n",
        "Next, we will do an *intuitive* subtraction of word embeddings as in\n",
        "\n",
        "1. Cricket without Tendulkar\n",
        "2. Football without Messi\n",
        "\n",
        "Note that the embedding vectors have 50 components corresponding to the 50-dimensional embedding of model suggested by the name '**glove-wiki-gigaword-50**'\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVVFzeQyR3Wb",
        "outputId": "b601c151-a1bc-4e35-f9bb-433efe2f65b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.7716      0.41267997 -1.725968   -0.10445005 -1.1475699  -0.854661\n",
            " -1.089      -0.08342999  0.62349    -1.67822    -0.2488078  -0.49199998\n",
            "  0.18756002 -1.67098     0.6117872   0.42784432  1.05656     0.91583097\n",
            " -0.03299999 -0.04422501  0.200326   -0.33737004  0.31068     1.37842\n",
            " -1.13689    -0.57445    -0.70685995  0.41552    -0.28937     0.54485\n",
            "  1.0492998   0.62732    -0.8105     -1.27723    -0.02612001  0.53963\n",
            " -0.14065999 -0.738244   -0.30487    -1.18129     0.05651999 -0.993618\n",
            " -0.911399   -0.09289992  0.535432    0.26259995 -0.63031     0.64473\n",
            "  0.77843     0.15099996]\n",
            "[-2.06898     0.66804904 -1.077512    0.79964995 -0.27109998 -0.26289004\n",
            " -0.881       0.377503   -0.10869002 -2.47329    -0.23453003 -0.58438\n",
            "  0.10404003 -0.52671003 -0.03030002  0.237764    0.19168997  1.60344\n",
            " -0.42980003  0.59058     0.59800005 -0.67075     0.45888     1.4538\n",
            " -1.15642    -1.63534    -1.1248189  -0.20879    -0.00812     0.25545004\n",
            "  1.92044     0.30049008  0.19949001 -0.675167   -0.15230002  0.13278002\n",
            " -0.29492003 -0.55414    -0.30988902 -0.34549004 -0.72603    -1.20504\n",
            " -0.45038998  0.51834     0.12448996  0.787596   -1.13398     0.91365004\n",
            " -0.280479    0.76741004]\n",
            "[ 1.29738    -0.25536907 -0.648456   -0.9041     -0.8764699  -0.59177095\n",
            " -0.208      -0.460933    0.73218     0.79506993 -0.01427777  0.09237999\n",
            "  0.08352    -1.14427     0.6420872   0.19008031  0.8648701  -0.6876091\n",
            "  0.39680004 -0.63480496 -0.39767405  0.33337998 -0.1482     -0.07537997\n",
            "  0.01952994  1.06089     0.41795897  0.62431    -0.28125     0.28939995\n",
            " -0.8711401   0.3268299  -1.00999    -0.602063    0.12618001  0.40684998\n",
            "  0.15426004 -0.18410403  0.00501901 -0.8358      0.78255     0.21142197\n",
            " -0.46100903 -0.6112399   0.41094202 -0.52499604  0.50367004 -0.26892006\n",
            "  1.0589089  -0.6164101 ]\n"
          ]
        }
      ],
      "source": [
        "# Cricket without Tendulkar\n",
        "a = loaded_word_vectors.get('cricket', None) - loaded_word_vectors.get('tendulkar', None)\n",
        "\n",
        "# Football without Messi\n",
        "b = loaded_word_vectors.get('football', None) - loaded_word_vectors.get('messi', None)\n",
        "print(a)\n",
        "print(b)\n",
        "\n",
        "# How different is cricket-without-tendulkar from\n",
        "# football-without-messi?\n",
        "print(a-b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6nbdX9IAYu6"
      },
      "source": [
        "---\n",
        "\n",
        "Understanding pen & paper versions of tensors w.r.t. their representations in the code\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhYNdr8DAj2V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3be9aa8a-3b14-4b70-a90d-d44e06338c3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3.], dtype=torch.float64)\n",
            "torch.Size([3])\n",
            "-------\n",
            "tensor([[1., 2., 3.]], dtype=torch.float64)\n",
            "torch.Size([1, 3])\n",
            "-------\n",
            "tensor([[1.],\n",
            "        [2.],\n",
            "        [3.]], dtype=torch.float64)\n",
            "torch.Size([3, 1])\n"
          ]
        }
      ],
      "source": [
        "# Pen & paper: 3-vector, Code: rank-1 tensor\n",
        "a_vector = torch.tensor([1.0, 2.0, 3.0], dtype = torch.float64)\n",
        "print(a_vector)\n",
        "print(a_vector.shape)\n",
        "print('-------')\n",
        "# Pen & paper: 1x3-matrix, Code: rank-2 tensor\n",
        "a_matrix_version1 = torch.tensor([[1.0, 2.0, 3.0]], dtype = torch.float64)\n",
        "print(a_matrix_version1)\n",
        "print(a_matrix_version1.shape)\n",
        "print('-------')\n",
        "# Pen & paper: 3x1-matrix, Code: rank-2 tensor\n",
        "a_matrix_version2 = torch.tensor([[1.0], [2.0], [3.0]], dtype = torch.float64)\n",
        "print(a_matrix_version2)\n",
        "print(a_matrix_version2.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VPICS8ggvvg"
      },
      "source": [
        "---\n",
        "\n",
        "A tensor of rank 3 corresponding to 4 time stamps (hourly), 3 samples (patients), 2 features (HR and BP). Assume that admission time is 9AM.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQAvgkRkWAM8",
        "outputId": "6fcdd20f-7e72-4c2f-840c-da7c984fdecc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 74., 128.],\n",
            "         [ 79., 116.],\n",
            "         [ 71., 116.]],\n",
            "\n",
            "        [[ 78., 118.],\n",
            "         [ 82., 124.],\n",
            "         [ 72., 128.]],\n",
            "\n",
            "        [[ 84., 138.],\n",
            "         [ 84., 130.],\n",
            "         [ 74., 120.]],\n",
            "\n",
            "        [[ 82., 126.],\n",
            "         [ 76., 156.],\n",
            "         [ 82., 132.]]])\n",
            "torch.Size([4, 3, 2])\n"
          ]
        }
      ],
      "source": [
        "# A rank-3 patient tensor with shape (4, 3, 2)\n",
        "# with meaning for\n",
        "# dim-0 as 4 hourly timestamps,\n",
        "# dim-1 as 3 patients, and\n",
        "# dim-2 as 2 features (HR and BP)\n",
        "# T = torch.tensor([[[HR, BP], [HR, BP], [HR, BP]],\n",
        "#                   [[HR, BP], [HR, BP], [HR, BP]],\n",
        "#                   [[HR, BP], [HR, BP], [HR, BP]],\n",
        "#                   [[HR, BP], [HR, BP], [HR, BP]]])\n",
        "T = torch.tensor([[[74., 128], [79, 116], [71, 116]],\n",
        "                 [[78, 118], [82, 124], [72, 128]],\n",
        "                 [[84, 138], [84, 130], [74, 120]],\n",
        "                 [[82, 126], [76, 156], [82, 132]]])\n",
        "print(T)\n",
        "print(T.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JV0fpSojg2EZ"
      },
      "source": [
        "---\n",
        "\n",
        "**Accessing elements of a tensor**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GbZuDYqg22n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2502166-34a1-4714-e20e-589b3d11773a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(132.)\n",
            "tensor([[ 74., 128.],\n",
            "        [ 79., 116.],\n",
            "        [ 71., 116.]])\n",
            "tensor([[ 82., 126.],\n",
            "        [ 76., 156.],\n",
            "        [ 82., 132.]])\n",
            "tensor([ 82., 132.])\n"
          ]
        }
      ],
      "source": [
        "## Accessing elements of a tensor\n",
        "# Rank-3 tensor T has axes order (timestamps, patients, features)\n",
        "\n",
        "# Element of T at postion 3 w.r.t. dim-0, position 2 w.r.t. dim-1,\n",
        "# position-1 w.r.t dim-2\n",
        "print(T[3, 2, 1]) # timestamp-3, patient-2, feature -1 also the BP of patient-2 at noon\n",
        "\n",
        "# Element-0 of object T which is also the info for all patients at\n",
        "print(T[0]) # patients' info at admission time\n",
        "print(T[-1])\n",
        "\n",
        "# Last admitted patient's info at noon\n",
        "print(T[3,2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-GpGq9-Ki0O"
      },
      "source": [
        "---\n",
        "\n",
        "Understanding shapes\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQMCQhgKKi0O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5146117-5d04-473e-d1cb-17a4fcaa07b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1., 2., 3.]]])\n",
            "torch.Size([1, 1, 3])\n"
          ]
        }
      ],
      "source": [
        "#a = torch.tensor([1.0, 2.0, 3.0]) # rank-1 tensor, a 3-vector in pen & paper\n",
        "#a = torch.tensor([[1.0, 2.0, 3.0]]) # rank-2 tensor, a 1x3-matrix in pen & paper\n",
        "#a = torch.tensor([[1.0], [2.0], [3.0]]) # rank-2 tensor, a 3x1-matrix in pen & paper\n",
        "a = torch.tensor([[[1.0, 2.0, 3.0]]]) # rank-3 tensor, a 1x1x3-tensor in pen & paper\n",
        "print(a)\n",
        "print(a.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9Qn5ZRUKi0O"
      },
      "source": [
        "---\n",
        "\n",
        "Broadcasting example that does not work\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2f2kpr7Ki0O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5b4be41-5523-4649-dbf4-86aefc0d3381"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 74., 128.],\n",
            "         [ 79., 116.],\n",
            "         [ 71., 116.]],\n",
            "\n",
            "        [[ 78., 118.],\n",
            "         [ 82., 124.],\n",
            "         [ 72., 128.]],\n",
            "\n",
            "        [[ 84., 138.],\n",
            "         [ 84., 130.],\n",
            "         [ 74., 120.]],\n",
            "\n",
            "        [[ 82., 126.],\n",
            "         [ 76., 156.],\n",
            "         [ 82., 132.]]])\n",
            "tensor([[ 74., 128.],\n",
            "        [ 78., 118.],\n",
            "        [ 84., 138.],\n",
            "        [ 82., 126.]])\n",
            "torch.Size([4, 3, 2])\n",
            "torch.Size([4, 2])\n"
          ]
        }
      ],
      "source": [
        "# How different are the patients compared to patient-0 across all timestamps\n",
        "T_patient0 = T[:, 0, :]\n",
        "print(T)\n",
        "print(T_patient0)\n",
        "print(T.shape)\n",
        "print(T_patient0.shape)\n",
        "#print(T - T_patient0) # does not work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3nD77lqKi0O"
      },
      "source": [
        "---\n",
        "\n",
        "Broadcasting example that works\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMnO06WAKi0O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe50a71b-83f0-49ea-a00f-d713e72e61e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 1, 2])\n"
          ]
        }
      ],
      "source": [
        "T_patient0 = T[:, 0, :]\n",
        "# Add a new dimension to a tensor using the unsqueeze() function\n",
        "T_patient0_new = torch.unsqueeze(T_patient0, 1)\n",
        "print(T_patient0_new.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqOyDnf3Ki0O"
      },
      "source": [
        "---\n",
        "\n",
        "**Exercise**: interpret $\\texttt{T[:, -1, :]}$\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcOySSCoKi0O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c77c054-c634-415b-cf5a-7bc878e9978e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 71., 116.],\n",
              "        [ 72., 128.],\n",
              "        [ 74., 120.],\n",
              "        [ 82., 132.]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Interpret T[:, -1, :]\n",
        "T[:, -1, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h04chuNiKi0P"
      },
      "source": [
        "---\n",
        "\n",
        "$l_2$ norm or the geometric length of a vector denoted as $\\lVert \\mathbf{a}\\rVert_2$ tells us how long a vector is. In 2-dimensions, $$\\mathbf{a}=\\begin{bmatrix}a_1\\\\a_2\\end{bmatrix}\\Rightarrow \\lVert\\mathbf{a}\\rVert_2 = \\sqrt{a_1^2+a_2^2}$$ and in $n$-dimensions, $$\\mathbf{a}=\\begin{bmatrix}a_1\\\\a_2\\\\\\vdots\\\\a_n\\end{bmatrix}\\Rightarrow\\lVert \\mathbf{a}\\rVert_2 = \\sqrt{a_1^2+a_2^2+\\cdots+a_n^2}.$$\n",
        "\n",
        "![vector norm](https://1drv.ms/i/c/37720f927b6ddc34/IQT817WmpQjlRqZ1R0d5Cfv6AUW6c4robL-gk06i9wmCaFU?width=500)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xB8gcEojKi0P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec7cba1d-624f-454f-d80f-b72386023176"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 76., 124.], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(145.4373, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "## l2 norm of a vector\n",
        "x = torch.tensor([76.0, 124.0], dtype = torch.float64)\n",
        "print(x)\n",
        "torch.norm(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAda9HkpKi0P"
      },
      "source": [
        "---\n",
        "\n",
        "Application of norm: how different is 'cricket-without-tendulkar' compared to 'football-without-messi'?\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Fd3nlNbKi0P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "630e13c0-0a81-4834-c891-78c1e408685e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3.7417)\n",
            "tensor(6.0760)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-219318566.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  print(torch.norm(torch.tensor(a))) # norm of 'cricket-without-tendulkar'\n"
          ]
        }
      ],
      "source": [
        "# Back to 'cricket-without-tendulkar' and 'football-without-messi'\n",
        "print(torch.norm(torch.tensor(a))) # norm of 'cricket-without-tendulkar'\n",
        "print(torch.norm(torch.tensor(b))) # norm of 'football-without-messi'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyrDDl5sKi0P"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "**Dot Product of Vectors**\n",
        "\n",
        "A scalar resulting from an elementwise multiplication and addition: $$\\mathbf{a}{\\color{cyan}\\cdot}\\mathbf{b} = {\\color{red}{a_1b_1}}+{\\color{green}{a_2b_2}}+\\cdots+{\\color{magenta}{a_nb_n}}$$\n",
        "\n",
        "The <font color=\"cyan\">dot</font> ${\\color{cyan}\\cdot}$ represents the computation of the dot product.\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKQsotj_Ki0P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c67e9998-5fb9-48f1-98ed-028ae4ddb0ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 4., 10., 18.], dtype=torch.float64)\n",
            "tensor(32., dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "## Dot product of vectors\n",
        "a = torch.tensor([1.0, 2.0, 3.0], dtype = torch.float64)\n",
        "b = torch.tensor([4.0, 5.0, 6.0], dtype = torch.float64)\n",
        "print(a * b) # This is called the Hadamard product\n",
        "print(torch.dot(a, b)) # This is called the dot product"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeuuav0bKi0P"
      },
      "source": [
        "---\n",
        "\n",
        "The dot product is a measure of similarity between vectors (or, how aligned they are geometrically).\n",
        "\n",
        "![dot product](https://1drv.ms/i/c/37720f927b6ddc34/IQTbcGSjdbhSTJ7J39d5BCWAAWS6-y5U6J87vHuDWeAqGwM?width=6000)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yx6wSzxwKi0P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "663b9e42-d5f0-4ca8-89eb-8e3785a1fe2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(10.)\n",
            "tensor(0.)\n",
            "tensor(-5.)\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([1.0, 2.0])\n",
        "b = torch.tensor([2.0, 4.0])\n",
        "c = torch.tensor([-2.0, 1.0])\n",
        "d = torch.tensor([-1.0, -2.0])\n",
        "print(torch.dot(a, b))\n",
        "print(torch.dot(a, c))\n",
        "print(torch.dot(a, d))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v64i6maMKi0P"
      },
      "source": [
        "---\n",
        "\n",
        "Cauchy-Schwarz inequality: for any two vectors $\\mathbf{x}$ and $\\mathbf{y},$ it is always true that $$-1\\leq\\frac{\\mathbf{x}\\cdot{\\mathbf{y}}}{\\lVert\\mathbf{x}\\rVert_2\\lVert\\mathbf{y}\\rVert_2}\\leq1.$$\n",
        "\n",
        "This is a normalized measure of similarity (or extent of alignment) between vectors which also referred to as the cosine similarity.\n",
        "\n",
        "This helps define the angle between two vectors $\\mathbf{x}$ and $\\mathbf{y}$ as $$\\angle(\\mathbf{x},\\mathbf{y}) = \\cos^{-1}\\left(\\frac{\\mathbf{x}\\cdot{\\mathbf{y}}}{\\lVert\\mathbf{x}\\rVert_2\\lVert\\mathbf{y}\\rVert_2}\\right)$$ which is a value from $0$ through $\\pi$ radians.\n",
        "\n",
        "Two ways to measure the difference between two vectors:\n",
        "\n",
        "![angle](https://1drv.ms/i/c/37720f927b6ddc34/IQQ03G17kg9yIIA3WokBAAAAAQi8FPV9YCebl5WnyEKJ3vg?width=213&height=400)\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yadHemz4Ki0P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dadf9d3-cf41-444a-fd63-6cd1fb390881"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.4142)\n",
            "tensor(0.6435)\n",
            "tensor(36.8699)\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([1.0, 2.0])\n",
        "y = torch.tensor([2.0, 1.0])\n",
        "\n",
        "#Linear difference between x & y\n",
        "print(torch.norm(x - y))\n",
        "\n",
        "# Angle between x and y in radians\n",
        "print(torch.acos(torch.dot(x,y) / (torch.norm(x) * torch.norm(y))))\n",
        "\n",
        "# Angle between x and y in degrees\n",
        "print((180.0/torch.pi)*(torch.acos(torch.dot(x,y) / (torch.norm(x) * torch.norm(y)))))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tgdXJPzKi0V"
      },
      "source": [
        "---\n",
        "\n",
        "Application of the Cauchy-Schwarz inequality: how different is \"cricket without tendulkar\" from \"football without messi\"?\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qq0JLTCCKi0V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77d1a93a-b781-4535-873c-66e6b8dc6ad6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.2349, dtype=torch.float64)\n",
            "tensor(0.7420, dtype=torch.float64)\n",
            "tensor(42.5126, dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor(loaded_word_vectors.get('cricket', None) - loaded_word_vectors.get('tendulkar', None),\n",
        "                 dtype = torch.float64)\n",
        "b = torch.tensor(loaded_word_vectors.get('football', None) - loaded_word_vectors.get('messi', None),\n",
        "                 dtype = torch.float64)\n",
        "\n",
        "# Linear difference between and a and b\n",
        "print(torch.norm(a-b))\n",
        "\n",
        "# Angle difference between a and b in radians (cosine similarity)\n",
        "print(torch.acos(torch.dot(a, b) / (torch.norm(a) * torch.norm(b))))\n",
        "\n",
        "# Angle difference between a and b in degrees\n",
        "print((180.0/torch.pi)*(torch.acos(torch.dot(a, b) / (torch.norm(a) * torch.norm(b)))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlXBojUjKi0W"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "**Hadamard Product of Vectors**\n",
        "\n",
        "A vector resulting from an elementwise multiplication: $$\\mathbf{a}{\\color{cyan}\\otimes}\\mathbf{b} = \\begin{bmatrix}{\\color{red}{a_1\\times b_1}}\\\\{\\color{green}{a_2\\times b_2}}\\\\\\vdots\\\\{\\color{magenta}{a_n\\times b_n}}\\end{bmatrix}.$$\n",
        "\n",
        "The $\\color{cyan}\\otimes$ represents the computation of the Hadamard product.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKHzoE1uKi0W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdb79081-c5c7-4b9b-e22e-d148b6da9cee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 4., 10., 18.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "## Hadamard product\n",
        "a = torch.tensor([1.0, 2.0, 3.0],dtype=torch.float64)\n",
        "b = torch.tensor([4.0, 5.0, 6.0],dtype=torch.float64)\n",
        "\n",
        "# Element-wise multiplication (Hadamard product)\n",
        "print(torch.mul(a,b))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtgRIhiAKi0W"
      },
      "source": [
        "---\n",
        "\n",
        "\n",
        "A matrix-vector product is simply a sequence of dot products of the rows of the matrix (seen as vectors) with the vector\n",
        "\n",
        "![matvec product](https://1drv.ms/i/c/37720f927b6ddc34/IQQ1cQ8fZdFmS4cnGkBlsZbAAaL2zMtzWdjHe-HCMt4UTA0?width=700)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJg1zd43Ki0W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bd2f6d4-6ee2-4244-8a9b-0ea19e82adc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 0.])\n"
          ]
        }
      ],
      "source": [
        "## Matrix-vector product\n",
        "A = torch.tensor([[1.0, 2.0, 4.0],\n",
        "                  [2.0, -1.0, 3.0]])\n",
        "x = torch.tensor([4.0, 2.0, -2.0])\n",
        "\n",
        "# Matrix-vector multiplication\n",
        "print(torch.matmul(A,x))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm0TmJ5qKi0W"
      },
      "source": [
        "---\n",
        "\n",
        "A matrix-matrix product is simply a sequence of matrix-vector products.\n",
        "\n",
        "![matmatprod](https://1drv.ms/i/c/37720f927b6ddc34/IQQ-B3z7tbWHQqBrW9k2ElDVAUc5fWzM24txLkgBK7f8Yac?width=550)\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bihe8XYnKi0W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "218852e3-7300-4bcb-8def-1d39f8b9d972"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0., 11.],\n",
            "        [ 0.,  7.]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "## Matrix-matrix product\n",
        "A = torch.tensor([[1.0, 2.0, 4.0],\n",
        "                  [2.0, -1.0, 3.0]], dtype = torch.float64)\n",
        "\n",
        "B = torch.tensor([[4, -1],\n",
        "                  [2, 0],\n",
        "                  [-2, 3]], dtype = torch.float64)\n",
        "print(torch.matmul(A,B))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iC47ldRMKi0W"
      },
      "source": [
        "---\n",
        "\n",
        "Matrix-matrix product using patient data matrix and a weights matrix:\n",
        "\n",
        "![patient dataset](https://1drv.ms/i/s!AjTcbXuSD3I3hspfrgklysOtJMOjaA?embed=1&width=800)\n",
        "\n",
        "$$\\mathbf{Z} = \\mathbf{XW}.$$\n",
        "\n",
        "$\\mathbf{Z}$ is called the raw scores matrix.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIgVxGlMKi0W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "240cb9b6-c6d5-492b-c353-16d370ce03a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patient data matrix X:\n",
            " tensor([[ 72.0000, 120.0000,  37.3000, 104.0000,  32.5000],\n",
            "        [ 85.0000, 130.0000,  37.0000, 110.0000,  14.0000],\n",
            "        [ 68.0000, 110.0000,  38.5000, 125.0000,  34.0000],\n",
            "        [ 90.0000, 140.0000,  38.0000, 130.0000,  26.0000],\n",
            "        [ 84.0000, 132.0000,  38.3000, 146.0000,  30.0000],\n",
            "        [ 78.0000, 128.0000,  37.2000, 102.0000,  12.0000]],\n",
            "       dtype=torch.float64)\n",
            "Weights matrix:\n",
            " tensor([[-0.1000,  0.5000,  0.3000],\n",
            "        [ 0.9000,  0.3000,  0.5000],\n",
            "        [-1.5000,  0.4000,  0.1000],\n",
            "        [ 0.1000,  0.1000, -1.0000],\n",
            "        [-1.2000,  0.5000, -0.8000]], dtype=torch.float64)\n",
            "#################\n",
            "tensor([[ 16.2500, 113.5700, -44.6700],\n",
            "        [ 47.2000, 114.3000, -27.0000],\n",
            "        [  6.1500, 111.9000, -72.9500],\n",
            "        [ 41.8000, 128.2000, -50.0000],\n",
            "        [ 31.5500, 126.5200, -74.9700],\n",
            "        [ 47.4000, 108.4800, -20.4800]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "# Patients data matrix\n",
        "X = torch.tensor([[72, 120, 37.3, 104, 32.5],\n",
        "                 [85, 130, 37.0, 110, 14],\n",
        "                 [68, 110, 38.5, 125, 34],\n",
        "                 [90, 140, 38.0, 130, 26],\n",
        "                 [84, 132, 38.3, 146, 30],\n",
        "                 [78, 128, 37.2, 102, 12]], dtype = torch.float64)\n",
        "print(f'Patient data matrix X:\\n {X}') #f-string in Python\n",
        "\n",
        "# Weights matrix\n",
        "W = torch.tensor([[-0.1, 0.5, 0.3],\n",
        "                  [0.9, 0.3, 0.5],\n",
        "                  [-1.5, 0.4, 0.1],\n",
        "                  [0.1, 0.1, -1.0],\n",
        "                  [-1.2, 0.5, -0.8]], dtype = torch.float64)\n",
        "print(f'Weights matrix:\\n {W}')\n",
        "\n",
        "Z =torch.matmul(X,W)\n",
        "print(\"#################\")\n",
        "print(Z)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "neuron 0 - diabetic\n",
        "neuron 1 - non diabetic\n",
        "neuron 2 - pre diabetic\n",
        "neurons are assigned based alphabetically based on output labels y"
      ],
      "metadata": {
        "id": "cde21PvxkSyW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6npqYm8XKi0W"
      },
      "source": [
        "---\n",
        "\n",
        "**Version-1** view of the matrix-matrix product $\\mathbf{Z} = \\mathbf{XW}$:\n",
        "\n",
        "*What a particular neuron understands about a particular patient.*\n",
        "\n",
        "![matrix-matrix product version-1](https://1drv.ms/i/c/37720f927b6ddc34/IQQdAOCwtndURKA-h4yvpTqlAYjBjlcweRSeMYkPvf7dwmQ?width=660)\n",
        "\n",
        "$$\\begin{align*}[\\mathbf{Z}]_{i,j} &= (i,j)\\text{-th element of }\\mathbf{Z}\\\\&=\\text{what the }j\\text{th neuron learns about the } i\\text{th patient}\\\\&=\\mathbf{x}^{(i)}\\cdot\\mathbf{w}_j\\\\& = {\\mathbf{x}^{(i)}}^\\mathrm{T}\\mathbf{w}_j\\\\\\Rightarrow \\underbrace{[\\mathbf{Z}]_{{\\color{yellow}0},{\\color{cyan}2}}}_{{\\color{yellow}0}\\text{th patient},\\,{\\color{cyan}2}\\text{nd neuron}} &= \\mathbf{x}^{({\\color{yellow}0})}\\cdot\\mathbf{w}_{{\\color{cyan}2}}\\\\ &= \\begin{bmatrix}72\\\\120\\\\37.3\\\\104\\\\32.5\\end{bmatrix}\\cdot\\begin{bmatrix}0.3\\\\0.5\\\\0.1\\\\-1.0\\\\-0.8\\end{bmatrix}\\\\ &= -44.67.\\end{align*}$$\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSAKJLJzKi0W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69528ffd-c0d4-400a-c93d-d6a61f0a1861"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-44.6700, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "## The (0, 2)-th element of the matrix-matrix product XW\n",
        "torch.dot(X[0,:], W[:,2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieBxSa97Ki0W"
      },
      "source": [
        "---\n",
        "\n",
        "**Version-2** view of the matrix-matrix product $\\mathbf{Z} = \\mathbf{XW}$:\n",
        "\n",
        "*What a particular neuron understands about all the patients.*\n",
        "\n",
        "![matrix-matrix product version-2](https://1drv.ms/i/c/37720f927b6ddc34/IQRm1-w-6TG0R4C4J4BizyzyAWIbcHzbEjgmx-0JFREdHsE?width=660)\n",
        "\n",
        "$$\\begin{align*}\\mathbf{z}_j &= \\mathbf{X}\\mathbf{w}_j\\\\&=\\text{what the } j\\text{th neuron learns about the all the patients}\\\\&=w_{j,0}\\times\\textbf{HR}+w_{j,1}\\times\\textbf{BP}+w_{j,2}\\times\\textbf{Temp}+w_{j,3}\\times\\textbf{Sugar}+w_{j,4}\\times\\textbf{Vitamin D}\\\\&= w_{j,0}\\mathbf{x}_0+w_{j,1}\\mathbf{x}_1+w_{j,2}\\mathbf{x}_2+w_{j,3}\\mathbf{x}_3+w_{j,4}\\mathbf{x}_4\\\\\\Rightarrow\\underbrace{\\mathbf{z}_{{\\color{cyan}0}}}_{{\\color{cyan}0}\\text{th neuron understanding}} &= \\underbrace{\\mathbf{X}}_{\\color{yellow}{\\text{all patients}}}\\ \\underbrace{\\mathbf{w}_{{\\color{cyan}0}}}_{{\\color{cyan}0}\\text{th neuron weights}}\\\\&= {\\color{cyan}{-0.1}}\\times\\begin{bmatrix}{\\color{yellow}{72}}\\\\{\\color{yellow}{85}}\\\\{\\color{yellow}{68}}\\\\{\\color{yellow}{90}}\\\\{\\color{yellow}{84}}\\\\{\\color{yellow}{78}}\\end{bmatrix}+{\\color{cyan}{0.9}}\\times\\begin{bmatrix}{\\color{yellow}{120}}\\\\{\\color{yellow}{130}}\\\\{\\color{yellow}{110}}\\\\{\\color{yellow}{140}}\\\\{\\color{yellow}{132}}\\\\{\\color{yellow}{128}}\\end{bmatrix}+({\\color{cyan}{-1.5}})\\times\\begin{bmatrix}{\\color{yellow}{37.3}}\\\\{\\color{yellow}{37.0}}\\\\{\\color{yellow}{38.5}}\\\\{\\color{yellow}{38.0}}\\\\{\\color{yellow}{38.3}}\\\\{\\color{yellow}{37.2}}\\end{bmatrix}+{\\color{cyan}{0.1}}\\times\\begin{bmatrix}{\\color{yellow}{104}}\\\\{\\color{yellow}{110}}\\\\{\\color{yellow}{125}}\\\\{\\color{yellow}{130}}\\\\{\\color{yellow}{146}}\\\\{\\color{yellow}{102}}\\end{bmatrix}+({\\color{cyan}{-1.2}})\\times\\begin{bmatrix}{\\color{yellow}{32.5}}\\\\{\\color{yellow}{14}}\\\\{\\color{yellow}{34}}\\\\{\\color{yellow}{26}}\\\\{\\color{yellow}{30}}\\\\{\\color{yellow}{12}}\\end{bmatrix}\\\\&=\\begin{bmatrix}16.25\\\\47.20\\\\6.15\\\\41.80\\\\31.55\\\\47.40\\end{bmatrix}.\\end{align*}$$\n",
        "\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaLsvzl7Ki0W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f54de560-79b8-4d4b-d6d0-cc48edc810c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([16.2500, 47.2000,  6.1500, 41.8000, 31.5500, 47.4000],\n",
              "       dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "## The 0-th column of the matrix-matrix product XW\n",
        "torch.matmul(X, W[:,0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0mdVoy8Ki0W"
      },
      "source": [
        "---\n",
        "\n",
        "**Version-3** view of the matrix-matrix product $\\mathbf{Z} = \\mathbf{XW}$:\n",
        "\n",
        "*What all neurons understand about a particular patient.*\n",
        "\n",
        "![matrix-matrix product version-3](https://1drv.ms/i/c/37720f927b6ddc34/IQRfO-qEJQ9mQYLH_f-lyjeQAaWV4FrDjTjaEHJpPB1PmCg?width=660)\n",
        "\n",
        "$$\\begin{align*}{\\mathbf{z}^{(i)}}^\\mathrm{T}&={\\mathbf{x}^{(i)}}^\\mathrm{T}\\mathbf{W}\\\\&= \\text{what is learned about the }i\\text{th patient by all the neurons}\\\\&=i\\text{th HR }\\times{\\mathbf{w}^{(0)}}^\\mathrm{T}+i\\text{th BP }\\times{\\mathbf{w}^{(1)}}^\\mathrm{T}+i\\text{th Temp }\\times{\\mathbf{w}^{(2)}}^\\mathrm{T}+i\\text{th Sugar }\\times{\\mathbf{w}^{(3)}}^\\mathrm{T}+i\\text{th Vitamin D }\\times{\\mathbf{w}^{(4)}}^\\mathrm{T}\\\\&=x^{(i)}_0\\times{\\mathbf{w}^{(0)}}^\\mathrm{T}+x^{(i)}_1\\times{\\mathbf{w}^{(1)}}^\\mathrm{T}+x^{(i)}_2\\times{\\mathbf{w}^{(2)}}^\\mathrm{T}+x^{(i)}_3\\times{\\mathbf{w}^{(3)}}^\\mathrm{T}+x^{(i)}_4\\times{\\mathbf{w}^{(4)}}^\\mathrm{T}\\\\\\underbrace{\\Rightarrow{{\\mathbf{z}^{({\\color{yellow}0})}}^\\mathrm{T}}}_{{\\color{yellow}{0}}\\text{th patient understanding}}&=\\underbrace{{{\\mathbf{x}^{({\\color{yellow}0})}}^\\mathrm{T}}}_{{\\color{yellow}{0}}\\text{th patient}}\\ \\underbrace{\\mathbf{W}}_{{\\color{cyan}{\\text{all neurons}}}}\\\\ &= {\\color{yellow}{72}}\\times\\begin{bmatrix}{\\color{cyan}{-0.1}} & {\\color{cyan}{0.5}} & {\\color{cyan}{0.3}}\\end{bmatrix} \\\\&+ {\\color{yellow}{120}}\\times\\begin{bmatrix}{\\color{cyan}{0.9}} & {\\color{cyan}{0.3}} & {\\color{cyan}{0.5}}\\end{bmatrix}\\\\&+{\\color{yellow}{37.3}}\\times\\begin{bmatrix}{\\color{cyan}{-1.5}} & {\\color{cyan}{0.4}} & {\\color{cyan}{0.1}}\\end{bmatrix}\\\\&+{\\color{yellow}{104}}\\times\\begin{bmatrix}{\\color{cyan}{0.1}} & {\\color{cyan}{0.1}} & {\\color{cyan}{-1.0}}\\end{bmatrix}\\\\&+{\\color{yellow}{32.5}}\\times\\begin{bmatrix}{\\color{cyan}{-1.2}} & {\\color{cyan}{0.5}} & {\\color{cyan}{-0.8}}\\end{bmatrix}\\\\&=\\begin{bmatrix}16.25 & 113.57 & -44.67\\end{bmatrix}.\\end{align*}$$\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieL5nR1uKi0W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4c0a05e-72c1-4ba8-9a89-f9f0cb52206e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 16.2500, 113.5700, -44.6700], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "## The 0-th row of the matrix-matrix product XW\n",
        "torch.matmul(X[0],W)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K65DLLv9Ki0W"
      },
      "source": [
        "---\n",
        "\n",
        "The softmax function: takes a $k$-vector $\\mathbf{z}$ as input and returns a vector $\\mathbf{a}$ of the same shape as the output which is referred to as the softmax-activated scores.\n",
        "\n",
        "$$\\begin{align*}\\mathbf{a}&=\\text{softmax}(\\mathbf{z})=\\begin{bmatrix}\\dfrac{e^{z_1}}{e^{z_1}+e^{z_2}+\\cdots+e^{z_k}}\\\\\\dfrac{e^{z_2}}{e^{z_1}+e^{z_2}+\\cdots+e^{z_k}}\\\\\\vdots\\\\\\dfrac{e^{z_k}}{e^{z_1}+e^{z_2}+\\cdots+e^{z_k}}\\end{bmatrix}.\\end{align*}$$\n",
        "\n",
        "In the following example, we consider a raw scores vector $\\mathbf{z}$ with 3 components which leads to the softmax-activated scores vectors $\\mathbf{a}$ which can be interpreted as the predicted probabilities that the sample belongs to each one of the output classes:\n",
        "\n",
        "![softmax](https://1drv.ms/i/s!AjTcbXuSD3I3hscmdol7J2G4GDo5WQ?embed=1&width=660)\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fH00wJreKi0W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcb37d87-7bae-4d02-efe4-c7acb13e034e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 5.6000,  6.4000, -4.5000], dtype=torch.float64)\n",
            "tensor([3.1002e-01, 6.8997e-01, 1.2736e-05], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "z = torch.tensor([5.6, 6.4, -4.5], dtype = torch.float64)\n",
        "print(z)\n",
        "softmax=torch.nn.Softmax(dim=0)\n",
        "a=softmax(z)\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Unmc1X-Ki0W"
      },
      "source": [
        "---\n",
        "\n",
        "Calculating the raw scores followed by the softmax-activated scores for the patient data matrix.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjY99XwBKi0W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6bac888-e07e-4eed-a269-a23ddf1ce33c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw zcores matrix:\n",
            " tensor([[ 16.2500, 113.5700, -44.6700],\n",
            "        [ 47.2000, 114.3000, -27.0000],\n",
            "        [  6.1500, 111.9000, -72.9500],\n",
            "        [ 41.8000, 128.2000, -50.0000],\n",
            "        [ 31.5500, 126.5200, -74.9700],\n",
            "        [ 47.4000, 108.4800, -20.4800]], dtype=torch.float64)\n",
            "tensor([[5.4258e-43, 1.0000e+00, 1.8934e-69],\n",
            "        [7.2250e-30, 1.0000e+00, 4.3071e-62],\n",
            "        [1.1840e-46, 1.0000e+00, 5.2561e-81],\n",
            "        [2.9989e-38, 1.0000e+00, 4.0618e-78],\n",
            "        [5.6892e-42, 1.0000e+00, 3.1189e-88],\n",
            "        [2.9737e-27, 1.0000e+00, 9.8488e-57]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "# Raw scores matrix (matrix-matrix multiplication)\n",
        "Z = torch.matmul(X,W)\n",
        "print(f'Raw zcores matrix:\\n {Z}')\n",
        "\n",
        "# Calculate the softmax scores\n",
        "softmax = torch.nn.Softmax(dim = 1)\n",
        "A = softmax(Z)\n",
        "print(A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmxgMVVyKi0W"
      },
      "source": [
        "---\n",
        "\n",
        "Standardization of data to get rid of the effects of units.\n",
        "\n",
        "The standard deviation of a vector is a measure of how much the components or elements of that vector typically deviate from their average value. For an $n$-vector $\\mathbf{x},$ the standard deviation is denoted and calculated as\n",
        "$$\\mathbf{x} = \\begin{bmatrix}x_1\\\\x_2\\\\\\vdots\\\\x_n\\end{bmatrix}\\Rightarrow\\text{std}(\\mathbf{x}) = \\sqrt{\\frac{\\left[x_1-\\text{avg}(\\mathbf{x})\\right]^2+\\cdots+\\left[x_n-\\text{avg}(\\mathbf{x})\\right]^2}{n}}.$$ The quantity inside the square root above is the average squared deviation which is also called the variance denoted as $$\\text{var}(\\mathbf{x}) = \\frac{\\left[x_1-\\text{avg}(\\mathbf{x})\\right]^2+\\cdots+\\left[x_n-\\text{avg}(\\mathbf{x})\\right]^2}{n}.$$\n",
        "\n",
        "This means $\\text{std}(\\mathbf{x}) = \\sqrt{\\text{var}(\\mathbf{x})}.$\n",
        "\n",
        "A large standard deviation indicates that the components of the vector typically deviate a lot from their average value or mean.\n",
        "\n",
        "The following component plot of a vector of heart rate values has the 1-standard deviation-above and below the mean represented as red-dotted lines:\n",
        "\n",
        "![standard deviation](https://1drv.ms/i/c/37720f927b6ddc34/IQQB_uF-TUO8SpoodLWz7sQPAc4POmYfY3hPjlX3vpYfKlY?width=540)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcnjS5rLKi0W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cd07b12-48c1-490e-c137-0846d2814374"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Heart rate vector:\n",
            " tensor([72., 85., 68., 90., 84., 78.], dtype=torch.float64)\n",
            "Average heart rate: 79.5\n",
            "Deviations in heart rate vector:\n",
            " tensor([ -7.5000,   5.5000, -11.5000,  10.5000,   4.5000,  -1.5000],\n",
            "       dtype=torch.float64)\n",
            "tensor(0., dtype=torch.float64)\n",
            "Squared-deviations in heart rate vector:\n",
            " tensor([ 56.2500,  30.2500, 132.2500, 110.2500,  20.2500,   2.2500],\n",
            "       dtype=torch.float64)\n",
            "Average squared deviation or variance in the heart rate: 58.583333333333336\n",
            "Standard deviation of the heart rate: 7.65397500213669\n",
            "Standardized heart rate vector:\n",
            "tensor([-0.9799,  0.7186, -1.5025,  1.3718,  0.5879, -0.1960],\n",
            "       dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "# Heart rate vector\n",
        "a = X[:, 0]\n",
        "print(f'Heart rate vector:\\n {a}')\n",
        "\n",
        "# BP vector\n",
        "b = X[:, 1]\n",
        "#print(f'Blood pressure vector:\\n {b}')\n",
        "\n",
        "# Average heart rate\n",
        "print(f'Average heart rate: {torch.mean(a)}')\n",
        "\n",
        "# Average BP\n",
        "#print(torch.mean(b))\n",
        "\n",
        "# Mean-centered heart rate vector or the de-meaned heart rate vector or the\n",
        "# deviations in heart rate vectors\n",
        "a_mc = a-torch.mean(a)\n",
        "print(f'Deviations in heart rate vector:\\n {a_mc}')\n",
        "\n",
        "# The average of the components of the mean-centered heart rate vector is zero\n",
        "print(torch.mean(a_mc))\n",
        "\n",
        "# The squared deviations vector\n",
        "print(f'Squared-deviations in heart rate vector:\\n {a_mc**2}')\n",
        "\n",
        "# The average of the squared deviations vector a.k.a. the variance in\n",
        "# the heart rate\n",
        "v = torch.mean(a_mc**2)\n",
        "print(f'Average squared deviation or variance in the heart rate: {v}')\n",
        "\n",
        "# Square-root of the average of the squared deviations vector\n",
        "# which is the same as the square root of the variance a.k.a. the\n",
        "# standard deviation in the heart rate\n",
        "s = torch.sqrt(v)\n",
        "print(f'Standard deviation of the heart rate: {s}')\n",
        "\n",
        "# Standardized heart rate vector a.k.a. the z-scores of the heart rate is\n",
        "# obtained by subtracting the mean heart rate and dividing by the\n",
        "# deviation of the heart rates\n",
        "z = a_mc/s #same as doing (a-torch.mean(a))/torch.std(a)\n",
        "print(f'Standardized heart rate vector:\\n{z}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrxQaP7lKi0X"
      },
      "source": [
        "---\n",
        "\n",
        "Suppose heart rate is measured in beats per hour instead of beats per minute. How do the z-scores look like now?\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oziae9YtKi0X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "646d031b-787e-4769-c1e9-9c67983e16be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Heart rate vector:\n",
            " tensor([4320., 5100., 4080., 5400., 5040., 4680.], dtype=torch.float64)\n",
            "Average heart rate: 4770.0\n",
            "Deviations in heart rate vector:\n",
            " tensor([-450.,  330., -690.,  630.,  270.,  -90.], dtype=torch.float64)\n",
            "Squared-deviations in heart rate vector:\n",
            " tensor([202500., 108900., 476100., 396900.,  72900.,   8100.],\n",
            "       dtype=torch.float64)\n",
            "Average squared deviation or variance in the heart rate: 210900.0\n",
            "Standard deviation of the heart rate: 459.23850012820134\n",
            "Standardized heart rate vector:\n",
            "tensor([-0.9799,  0.7186, -1.5025,  1.3718,  0.5879, -0.1960],\n",
            "       dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "# Suppose heart rate is measured in beats per hour instead of beats per minute\n",
        "a = X[:, 0]*60\n",
        "print(f'Heart rate vector:\\n {a}')\n",
        "\n",
        "\n",
        "# Average heart rate\n",
        "print(f'Average heart rate: {torch.mean(a)}')\n",
        "\n",
        "\n",
        "# Mean-centered heart rate vector or the de-meaned heart rate vector or the\n",
        "# deviations in heart rate vectors\n",
        "a_mc = a - torch.mean(a)\n",
        "print(f'Deviations in heart rate vector:\\n {a_mc}')\n",
        "\n",
        "# The average of the components of the mean-centered heart rate vector is zero\n",
        "#print(torch.mean(a_mc))\n",
        "\n",
        "# The squared deviations vector\n",
        "print(f'Squared-deviations in heart rate vector:\\n {a_mc**2}')\n",
        "\n",
        "# The average of the squared deviations vector a.k.a. the variance in\n",
        "# the heart rate\n",
        "v = torch.mean(a_mc**2)\n",
        "print(f'Average squared deviation or variance in the heart rate: {v}')\n",
        "\n",
        "# Square-root of the average of the squared deviations vector\n",
        "# which is the same as the square root of the variance a.k.a. the\n",
        "# standard deviation in the heart rate\n",
        "s = torch.sqrt(v)\n",
        "print(f'Standard deviation of the heart rate: {s}')\n",
        "\n",
        "# Standardized heart rate vector a.k.a. the z-scores of the heart rate\n",
        "z = a_mc / s\n",
        "print(f'Standardized heart rate vector:\\n{z}')\n",
        "# The z-scores are the same as before when the heart rate was in beats per minute"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "colab",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}